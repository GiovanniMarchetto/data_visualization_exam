{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Visualization Exam"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import plotly.graph_objs as go\r\n",
    "import plotly.express as px\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data acquisition\r\n",
    "CSV file creation from raw data and loading the CSV file into the program."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataFolderName = \"data\"\r\n",
    "fileName = dataFolderName + '/DCSC_RACLI_01092021113430630.csv'\r\n",
    "df = pd.read_csv(fileName)      # load data from CSV to program\r\n",
    "df.head() # data loaded"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data parsing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: Check for errors in data\r\n",
    "#       total is equal to the arithmetic mean of the parts? not seem\r\n",
    "#       find missing data\r\n",
    "#   \tcheck that value apprendista < operaio < dirigente (for territory)\r\n",
    "\r\n",
    "print('\\nBefore remove duplicates: ' + str(len(df)) + ' rows')\r\n",
    "df.drop_duplicates()\r\n",
    "print('After remove duplicates:  ' + str(len(df)) + ' rows')\r\n",
    "\r\n",
    "# are values reasonable?\r\n",
    "print('\\nMin value is ' + str(df['Value'].min()))\r\n",
    "print('Max value is ' + str(df['Value'].max()))\r\n",
    "\r\n",
    "# TODO: Change type\r\n",
    "\r\n",
    "# TODO: Choose the level for hierachical data\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: Transform the data\r\n",
    "df['Territorio'] = df['Territorio'].str.replace(' / ','/')\r\n",
    "\r\n",
    "# TODO: rename and translate df fields\r\n",
    "# rename sectors in english\r\n",
    "it_sec_names = df.query('`Ateco 2007`!=\"TOTALE\" & `ATECO_2007`>=\"A\" & `ATECO_2007`<=\"Z\"')['Ateco 2007'].drop_duplicates().reset_index(drop=True)\r\n",
    "\r\n",
    "en_sec_names = []\r\n",
    "\r\n",
    "import googletrans #--->pip install googletrans==4.0.0-rc1\r\n",
    "from googletrans import Translator,constants\r\n",
    "translator = Translator()\r\n",
    "\r\n",
    "# print(sectors_name[0])\r\n",
    "for sector in it_sec_names:\r\n",
    "    translation = translator.translate(sector, src=\"it\", dest=\"en\")\r\n",
    "    en_sec_names.append(translation.text)\r\n",
    "\r\n",
    "for i in range(0, len(it_sec_names)):\r\n",
    "    df.loc[df['Ateco 2007']==it_sec_names[i],\"Ateco 2007\"] = en_sec_names[i]\r\n",
    "\r\n",
    "# df_sectors_tot\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data filtering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df2 = df.copy()\r\n",
    "\r\n",
    "# unique data\r\n",
    "del df2['TIPO_DATO7'] # always the same (HOUWAG_ENTEMP_AV_MI)\r\n",
    "del df2['Tipo dato']  # always the same (Retribuzione lorda oraria per ora retribuita delle posizioni lavorative dipendenti in euro (media).)\r\n",
    "\r\n",
    "# ridondance of information\r\n",
    "df2 = df2.drop(['SEXISTAT1', 'ETA1_A','PROFILO_PROF','CLLVT','Seleziona periodo'], axis=1)\r\n",
    "# del df2['ATECO_2007']\r\n",
    "\r\n",
    "df2 = df2[df2['Flag Codes'] != 'c'] # delete incomplete data\r\n",
    "\r\n",
    "del df2['Flags']\r\n",
    "del df2['Flag Codes']\r\n",
    "\r\n",
    "df2.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data mining"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# granularity of sectors exists only for entire Italy (no territorial granularity)\r\n",
    "df_sectors = df2.query('`Ateco 2007`!=\"TOTALE\"')\r\n",
    "\r\n",
    "# choose granularity of sectors\r\n",
    "df_sectors = df_sectors.query('`ATECO_2007`>=\"A\" & `ATECO_2007`<=\"Z\"')\r\n",
    "\r\n",
    "df_sectors = df_sectors.drop(['Territorio', 'ATECO_2007'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_territory = df2.query('`Ateco 2007`==\"TOTALE\"')\r\n",
    "df_territory = df_territory.drop(['Ateco 2007', 'ATECO_2007'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: start with univariate analysis (one variable at a time), continue with multivariate analysis"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parameters for questions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import geopandas as gpd\r\n",
    "import json\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import plotly.express as px\r\n",
    "import shutil as sh\r\n",
    "\r\n",
    "# PARAMETERS                    # TODO : all common parameters should be declared at the beginning\r\n",
    "dataFolderName = 'data'\r\n",
    "geoJsonFolder = dataFolderName+'/geoJson/'\r\n",
    "figureOutputFolder = 'exported_figures'\r\n",
    "dataFileName = dataFolderName + '/DCSC_RACLI_01092021113430630.csv' # for data loading (salaries)\r\n",
    "outputWidthImage = 10000\r\n",
    "outputHeightImage = 7000\r\n",
    "\r\n",
    "colors_palette = ['#003a2b','#249e89','#f5f5f5','#d86e58','#6a0000']\r\n",
    "\r\n",
    "exportFigure = False    # set to true if you want to export the figureif exportFigure:\r\n",
    "\r\n",
    "if os.path.exists(figureOutputFolder):\r\n",
    "    sh.rmtree(figureOutputFolder)\r\n",
    "os.makedirs(f'{figureOutputFolder}/question 1')\r\n",
    "os.makedirs(f'{figureOutputFolder}/question 2')\r\n",
    "os.makedirs(f'{figureOutputFolder}/question 3')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 1\r\n",
    "In private companies, are salaries higher in northern Italy than in the south? (Where do people earn more? Maybe divide by principal/worker/apprentice)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utility functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Utility functions to read data from csv and shape files, remove useless columns frome the dataframe and transfrom the data for the program\r\n",
    "\r\n",
    "def loadDataFromCSV(forceUpdate=False):\r\n",
    "    '''\r\n",
    "    Load data about salaries into the program.\r\n",
    "    Returns a Pandas Dataframe.\r\n",
    "    If the parameter forceUpdate is set to True, this function will\r\n",
    "    reload the dataframe from the file even if it was already loaded\r\n",
    "    (to be used when suspecting the data are chenged on the file).\r\n",
    "    '''\r\n",
    "\r\n",
    "    df_ref = {}\r\n",
    "\r\n",
    "    def closureFun(forceUpdate=False):\r\n",
    "\r\n",
    "        if (forceUpdate==True):\r\n",
    "            df_ref.clear() # clear the df\r\n",
    "        \r\n",
    "        if (len(df_ref)==0):\r\n",
    "\r\n",
    "            df = pd.read_csv(dataFileName).drop_duplicates()\r\n",
    "\r\n",
    "            # Transform the data and remove useless columns\r\n",
    "            df['Territorio'] = df['Territorio'].str.replace(' / ','/')\r\n",
    "            df = df.drop('TIPO_DATO7', axis=1) # always the same (HOUWAG_ENTEMP_AV_MI)\r\n",
    "            df = df.drop('Tipo dato', axis=1)  # always the same (Retribuzione lorda oraria per ora retribuita delle posizioni lavorative dipendenti in euro (media).)\r\n",
    "            df = df.drop(['SEXISTAT1', 'ETA1_A','PROFILO_PROF','CLLVT','Seleziona periodo'], axis=1)  # ridondance of information\r\n",
    "            df = df[df['Flag Codes'] != 'c'].drop(['Flags','Flag Codes'], axis=1) # delete incomplete data and drop columns with corresponding flag ('c' is the flag for hidden data)\r\n",
    "\r\n",
    "            # Transform data for consistency with datasets of geocoords\r\n",
    "            df.loc[df['Territorio']==\"Forlì-Cesena\", \"Territorio\"] = \"Forli'-Cesena\"\r\n",
    "\r\n",
    "            # Save the dataframe\r\n",
    "            df_ref[0] = df\r\n",
    "\r\n",
    "        return df_ref[0]\r\n",
    "    \r\n",
    "    return closureFun\r\n",
    "\r\n",
    "loadDataFromCSV = loadDataFromCSV() # use the closure\r\n",
    "    \r\n",
    "\r\n",
    "\r\n",
    "def getDataAboutTerritory():\r\n",
    "    '''\r\n",
    "    Returns data about salaries in territories (data about sectors are excluded).\r\n",
    "    '''\r\n",
    "    return loadDataFromCSV().query('`Ateco 2007`==\"TOTALE\"').drop(['Ateco 2007', 'ATECO_2007'], axis=1)\r\n",
    "\r\n",
    "\r\n",
    "def getDataAboutProvinces():\r\n",
    "    '''\r\n",
    "    Returns data about salaries in provinces (data about sectors, regions, entire Italy are excluded).\r\n",
    "    '''\r\n",
    "    df_territory = getDataAboutTerritory()\r\n",
    "    years = loadDataFromCSV()['TIME'].drop_duplicates()\r\n",
    "\r\n",
    "    # Note: this column is present also in geo-data and can be used to join the datasets\r\n",
    "    df_territory[\"TerritorioAnno\"] = df_territory[\"Territorio\"] + df_territory['TIME'].astype(str)\r\n",
    "    return df_territory[df_territory['ITTER107'].str.contains('.{5}')].drop('ITTER107', axis=1)   # for provinces, 'ITTER107' code is 5 chars long\r\n",
    "\r\n",
    "\r\n",
    "def getDataAboutProvincesInDictHavingYearsAsKey(years=-1):\r\n",
    "    '''\r\n",
    "    Returns data about salaries in provinces (data about sectors, regions, entire Italy are excluded),\r\n",
    "    organized in a dictionary having years (the parameters) as keys.\r\n",
    "    Params: years, e.g.: years=range(2014,2018).\r\n",
    "    If the parameter years is not specified, all the years are considered.\r\n",
    "    '''\r\n",
    "    dataProvinces = getDataAboutProvinces()\r\n",
    "    if(years==-1):\r\n",
    "        years = dataProvinces['TIME'].drop_duplicates()\r\n",
    "\r\n",
    "    return {year: dataProvinces.query(f'TIME=={year}').drop_duplicates() for year in years}\r\n",
    "\r\n",
    "\r\n",
    "def getProvinceSalaryvalue(year=-1):        # TODO: take a list as input parameter\r\n",
    "    '''\r\n",
    "    Returns a Pandas Dataframe with three columns: one for Province names (\"Territorio\"), the second for the\r\n",
    "    year (\"TIME\") and the third for the corresponding salary value (\"Value\"); column names are the ones inside\r\n",
    "    the brackets (\"Territorio\", \"TIME\", \"Value\").\r\n",
    "    Returned data refer to the year which is given as parameter.\r\n",
    "    If the year parameter is not specified, also the column 'TIME' is returned, with the corresponding year\r\n",
    "    '''\r\n",
    "    df_years = getDataAboutProvincesInDictHavingYearsAsKey([year]) if year!=-1 \\\r\n",
    "                                                             else getDataAboutProvincesInDictHavingYearsAsKey()\r\n",
    "    \r\n",
    "    years = sorted(df_years.keys())\r\n",
    "\r\n",
    "    df_years = {year: df_years[year].query(\"Sesso=='totale' & `Classe di età`=='totale' & `Qualifica contrattuale`=='totale' & `Classe di dipendenti`=='totale'\")   \\\r\n",
    "                                    .drop(['Sesso', 'Classe di età', 'Qualifica contrattuale', 'Classe di dipendenti'], axis=1)                                     \\\r\n",
    "                for year in years}\r\n",
    "\r\n",
    "    # Categorization of Salary values (grouping in categories)\r\n",
    "    valueCountedData = {year: np.floor(df_years[year][\"Value\"]).astype(int).value_counts() for year in years}\r\n",
    "\r\n",
    "    # NOTE: This part should be part of data transforming? But ranges should adapt to the context?\r\n",
    "\r\n",
    "    salaryCategoryBorders = range(9,20,2)   # same category subdivion for all years\r\n",
    "    for year in years:\r\n",
    "        oldCategory=0\r\n",
    "        df = df_years[year]\r\n",
    "        for category in salaryCategoryBorders:\r\n",
    "            numberProvinceInThisCategory = sum([valueCountedData[year][key] for key in np.intersect1d(valueCountedData[year].keys().tolist(), range(oldCategory,category))])\r\n",
    "            df.loc[(oldCategory<=df['Value']) & ( (df['Value']<category) | (df['Value']>=salaryCategoryBorders[-1]) ), \"SalaryCategory\"] =                      \\\r\n",
    "                (f\"{oldCategory} ≤ \" if oldCategory > salaryCategoryBorders[0] else \"        \")                                                                 \\\r\n",
    "                + \"..\"                                                                                                                                          \\\r\n",
    "                + (f\" < {category}\"  if category < salaryCategoryBorders[-1] else \"        \")                                                                   \\\r\n",
    "                + f\"  €/hr\\t({numberProvinceInThisCategory} provinces)\"\r\n",
    "            oldCategory = category\r\n",
    "        \r\n",
    "        # sort (needed to respect the range-scale in plots if categorization is used)\r\n",
    "        df.sort_values(by=['Value'], ascending=True, inplace=True)\r\n",
    "        \r\n",
    "        df_years[year] = df\r\n",
    "\r\n",
    "    df = pd.concat(tuple(df_years[year] for year in years))\r\n",
    "\r\n",
    "    # sort (needed to respect the range-scale in plots if categorization is used)\r\n",
    "    #   Sort (first) ascending wrt 'TIME' (oldest first) then descending wrt 'Value'\r\n",
    "    df['Value'] = -df['Value']  # invert sign, so 'Value' can be sorted descending\r\n",
    "    df.sort_values(by=['TIME', 'Value'], ascending=True, inplace=True)\r\n",
    "    df['Value'] = -df['Value']  # restore the correct sign\r\n",
    "    \r\n",
    "    return  df\r\n",
    "\r\n",
    "\r\n",
    "def avgSalary(territory='Italia', year=-1):\r\n",
    "    '''\r\n",
    "    Returns the average salary value in a given territory for a given year (parameters).\r\n",
    "    The default value for the territory is entire Italy.\r\n",
    "    If the year is not specified, the average value is computed over all the years which\r\n",
    "    are available.\r\n",
    "    '''\r\n",
    "    query = f\"Territorio=='Italia' & Sesso=='totale' & `Classe di età`=='totale' & `Qualifica contrattuale`=='totale' & `Classe di dipendenti`=='totale'\"   \\\r\n",
    "            + (f\" & `TIME=={year}\" if year!=-1 else \"\")\r\n",
    "    return round(100*getDataAboutTerritory().query(query)['Value'].mean())/100  # round(100*..)/100 is used to have two decimal digits\r\n",
    "\r\n",
    "# Utility functions for geo-data\r\n",
    "def readGeoDataToDictHavingYearAsKey():\r\n",
    "    '''\r\n",
    "    Import data Geo-data (coordinates) and returns the dictionary having as key\r\n",
    "    the year and as values the dataframe with geodata loaded from shape files.\r\n",
    "    '''\r\n",
    "    map_df = {} # dictionary, year as key\r\n",
    "    map_df[2014] = gpd.read_file(f'{dataFolderName}/province_shapes/Prov01012014_g/Prov01012014_g_WGS84.shp')\r\n",
    "    map_df[2014]['DEN_PCM'] = map_df[2014]['DEN_PROV']  # duplicate this column to make the dataframe compliant with those of subsequent years \r\n",
    "    map_df[2014].loc[ map_df[2014].DEN_PCM==\"Forlì-Cesena\",\"DEN_PCM\" ] = \"Forli'-Cesena\"\r\n",
    "\r\n",
    "    for year in range(2015,2018):\r\n",
    "        fp = f'{dataFolderName}/province_shapes/ProvCM01012017_g/ProvCM01012017_g_WGS84.shp' # data updated to 1st Jan 2017 work for our purposes\r\n",
    "        map_df[year] = gpd.read_file(fp) #reading the file stored in variable fp\r\n",
    "        map_df[year].loc[ map_df[year].DEN_PCM==\"Aosta\",\"DEN_PCM\" ] = \"Valle d'Aosta/Vallée d'Aoste\"\r\n",
    "        map_df[year].loc[ map_df[year].DEN_PCM==\"Massa Carrara\",\"DEN_PCM\" ] = \"Massa-Carrara\"\r\n",
    "        map_df[year].loc[ map_df[year].DEN_PCM==\"Bolzano\",\"DEN_PCM\" ] = \"Bolzano/Bozen\"\r\n",
    "\r\n",
    "    # Note: territories coords change over the year, hence we save the year near the territory names\r\n",
    "    for year in map_df.keys():\r\n",
    "        map_df[year][\"TerritorioAnno\"] = map_df[year][\"DEN_PCM\"] + str(year)\r\n",
    "    \r\n",
    "    return map_df\r\n",
    "\r\n",
    "\r\n",
    "# Function to convert (project) coordinates to latitude/longitude\r\n",
    "def convertCrsToLatLong(inputGeopandasDf, inplace=False):\r\n",
    "    '''\r\n",
    "    Convert the geo-coordinates of the iunput GeoPandas Dataframe to EPSG:4326 (latitude and longitude)\r\n",
    "    and returns a new GeoPandas dataframe having the data in the new coordinates system.\r\n",
    "    You can specify the parameter inplace=True if you want to change the coordinate system \"inplace\",\r\n",
    "    i.e., directly in the input GeoPandas Dataframe.\r\n",
    "    '''\r\n",
    "    outputGeopandasDf = inputGeopandasDf.set_geometry(\"geometry\") # The original geometry column is replaced with \"geometry\" (if it was different).\r\n",
    "    outputGeopandasDf = outputGeopandasDf.to_crs(\"EPSG:4326\", inplace=inplace)\r\n",
    "    return outputGeopandasDf\r\n",
    "    \r\n",
    "\r\n",
    "def createGeoJsonFromFile(geoJsonFolder, shapeDataDictYears, convertCrsToLatLongFlag=True):\r\n",
    "    '''\r\n",
    "    Creates GeoJson files in the folder whose path is specified as parameter as string,\r\n",
    "    from the given dictionary having years as keys and the corresponding shape file data\r\n",
    "    (GeoPandas dataframe) as values.\r\n",
    "    The parameter shapeDataDictYears can also be the shape file data directly, i.e. the\r\n",
    "    value of onlyh one record of a dictionary.\r\n",
    "    Specify the parameter convertCrsToLatLongFlag=False if you do NOT want to convert the\r\n",
    "    geo-coordinate system to EPSG:4326; default is True.\r\n",
    "    Returns a dictionary having as key the years (the same as the input dictionary) and\r\n",
    "    the corresponding GeoJson data as values.\r\n",
    "    '''\r\n",
    "    geoJsonData = {}\r\n",
    "    if not os.path.exists(geoJsonFolder):\r\n",
    "        os.makedirs(geoJsonFolder)              # TODO : check for issues (everything correct? Warning: '\"writeGeoJson\" is not accessed', as if os.makedirs was never used)\r\n",
    "\r\n",
    "    isInputShapeDataAsDict = type(shapeDataDictYears) is dict # true id a dictionary is given as input parameter\r\n",
    "    if(not isInputShapeDataAsDict):\r\n",
    "        shapeDataDictYears = {'': shapeDataDictYears}    # converted to dict to use the same code\r\n",
    "\r\n",
    "    for year in shapeDataDictYears.keys():\r\n",
    "        if(convertCrsToLatLongFlag):\r\n",
    "            shapeDataDictYears[year] = convertCrsToLatLong(shapeDataDictYears[year])\r\n",
    "        geoJsonPathThisYear = geoJsonFolder+str(year)+'.json'\r\n",
    "        shapeDataDictYears[year].to_file(geoJsonPathThisYear, driver=\"GeoJSON\")\r\n",
    "        with open(geoJsonPathThisYear, encoding=\"utf-8\") as geofile:\r\n",
    "            geoJsonData[year] = json.load(geofile)    \r\n",
    "    \r\n",
    "    return geoJsonData if(isInputShapeDataAsDict) \\\r\n",
    "                       else geoJsonData[[v for v in shapeDataDictYears.keys()][0]]\r\n",
    "\r\n",
    "\r\n",
    "def loadDataMultipleYears(provinceNames=[], years=[]):\r\n",
    "    '''\r\n",
    "    Returns the GeoJson data and the dataframe of provinces (only with territories, economic sectors\r\n",
    "    excluded) for all the years. The two dataframes (geoJsonData, df_province) have to be unpacked.\r\n",
    "    This function can be used to rapidly load both geo-data and data about salaries in provinces, over\r\n",
    "    all the years (province granularity only).\r\n",
    "    If the parameter provinceNames is specified, only data about the desired provinces will be loaded\r\n",
    "    (a list is expected).\r\n",
    "    If the parameter years (a list is expected) is specified, only data about selected years will be\r\n",
    "    returned\r\n",
    "    '''\r\n",
    "\r\n",
    "    # Read geo-data\r\n",
    "    map_df = readGeoDataToDictHavingYearAsKey() # dictionary, year as key\r\n",
    "\r\n",
    "    # Load data about salaries for each province\r\n",
    "    df_province = getProvinceSalaryvalue()\r\n",
    "\r\n",
    "    if(len(years)>0):   # filter according to years\r\n",
    "        df_province = df_province.query(' | '.join({f\"(TIME=={year})\" for year in years}))\r\n",
    "        map_df = {year: map_df[year] for year in years}\r\n",
    "    else:\r\n",
    "        years = map_df.keys()\r\n",
    "\r\n",
    "    if(len(provinceNames)>0):\r\n",
    "        df_province = df_province.query(' | '.join({f'(Territorio==\"{provinceName}\")' for provinceName in provinceNames}))\r\n",
    "        map_df = {year: map_df[year].query(' | '.join({f'(DEN_PCM==\"{provinceName}\")' for provinceName in provinceNames})) for year in years}\r\n",
    "    \r\n",
    "    # Create GeoJson from SHP dataframe (union over years of shp files)\r\n",
    "    geoJsonData = createGeoJsonFromFile(geoJsonFolder, pd.concat(tuple(convertCrsToLatLong(map_df[year]) for year in years)))\r\n",
    "\r\n",
    "\r\n",
    "    return geoJsonData, df_province"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot maps"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "# Load both geodata and data about salaries (only for the desired province), for each year\r\n",
    "\r\n",
    "for year in range(2014,2018):\r\n",
    "    geoJsonData, df_province = loadDataMultipleYears(years=[year])\r\n",
    "\r\n",
    "    print(f\"\\n\\nYear: {year}\")\r\n",
    "    maxSalary = max(df_province['Value'])\r\n",
    "    minSalary = min(df_province['Value'])\r\n",
    "    best_province  = df_province.query(f\"Value=={maxSalary}\")\r\n",
    "    worst_province = df_province.query(f\"Value=={minSalary}\")\r\n",
    "    if(len(best_province)>1 or len(worst_province)>1):\r\n",
    "        print(\"WARNING: query returned more than one result, only the first result is showed\")\r\n",
    "    \r\n",
    "    print(f\"\\tBest province{'s' if len(best_province)>1 else ''}:\\t{str(best_province.to_dict('records'))}\")\r\n",
    "    print(f\"\\tWorst province{'s' if len(worst_province)>1 else ''}:\\t{str(worst_province.to_dict('records'))}\")\r\n",
    "\r\n",
    "    # Choropleth by categories\r\n",
    "\r\n",
    "    fig = px.choropleth(\r\n",
    "        data_frame=df_province, \r\n",
    "        geojson=geoJsonData, \r\n",
    "        locations='Territorio',              # name of dataframe column\r\n",
    "        featureidkey='properties.DEN_PCM',   # path to field in GeoJSON feature object with which to match the values passed in to locations\r\n",
    "        color='SalaryCategory',\r\n",
    "        color_discrete_sequence=colors_palette,      # for discrete scale of colors\r\n",
    "        center={\"lat\": 42, \"lon\": 13},\r\n",
    "        projection='mercator',\r\n",
    "        labels={'SalaryCategory': 'Average hourly gross salary'},\r\n",
    "        hover_name='Territorio',\r\n",
    "        hover_data={'Value':True, 'SalaryCategory':False, 'Territorio': False}          # TODO: improve this (see \"hovertemplate\")\r\n",
    "    )\r\n",
    "    fig.update_traces(marker=dict(opacity=1, line=dict(color='black', width=0.1)))      # TODO: look for \"hovertemplate, https://plotly.com/python/reference/choropleth/#choropleth-hovertemplate\"\r\n",
    "    fig.update_layout(\r\n",
    "        plot_bgcolor='white',\r\n",
    "        font=dict(color='dimgray'),\r\n",
    "        title='Salaries in private companies',\r\n",
    "        margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\r\n",
    "        legend_itemsizing='trace'               # Determines if the legend items symbols scale with their corresponding \"trace\" attributes or remain \"constant\" independent of the symbol size on the graph. # TODO: NOT working\r\n",
    "    )\r\n",
    "    fig.update_geos(showcountries=False, showcoastlines=False, showland=False, fitbounds=\"locations\")\r\n",
    "    fig.show(\"notebook\")\r\n",
    "\r\n",
    "\r\n",
    "    # Export the figure\r\n",
    "    if exportFigure:\r\n",
    "        fig.write_image(f\"{figureOutputFolder}/question 1/geoMap{year}.svg\")\r\n",
    "        fig.write_image(f\"{figureOutputFolder}/question 1/geoMap{year}.png\", width=outputWidthImage, height=outputHeightImage)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 2\r\n",
    "Do women earn less than men in Italy in private companies? Where is the most difference?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_sex = df_territory.query('Sesso!=\"totale\" & Territorio==\"Italia\"')[['Sesso','TIME','Value']]\r\n",
    "# df_sex = df_sex.drop(['Classe di età','Qualifica contrattuale','Classe di dipendenti'],axis=1)\r\n",
    "# df_sex"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot line chart"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labels = ['Male','Female','Gap']\r\n",
    "colors = ['#5b8592','#cf6651','#171717']\r\n",
    "first_year = df_sex.TIME.min()\r\n",
    "last_year = df_sex.TIME.max()\r\n",
    "\r\n",
    "x_year = np.arange(first_year,last_year+1)\r\n",
    "x_data = np.vstack((x_year,)*3)\r\n",
    "\r\n",
    "df_sex.sort_values(by='TIME')\r\n",
    "df_mal = df_sex.query('Sesso==\"maschi\"')['Value'].to_list()\r\n",
    "df_fem = df_sex.query('Sesso==\"femmine\"')['Value'].to_list()\r\n",
    "y_mal = []\r\n",
    "y_fem = []\r\n",
    "gap = []\r\n",
    "for i in range(0,last_year-first_year+1):\r\n",
    "    gap.append(round(df_mal[i] - df_fem[i],2))\r\n",
    "    if i != 0:\r\n",
    "        y_mal.append(round(df_mal[i] - df_mal[i-1],2))\r\n",
    "        y_fem.append(round(df_fem[i] - df_fem[i-1],2))\r\n",
    "    if i == 0:\r\n",
    "        y_mal.append(0)\r\n",
    "        y_fem.append(0)\r\n",
    "y_data = np.array([y_mal,y_fem,gap])\r\n",
    "\r\n",
    "fig = go.Figure()\r\n",
    "\r\n",
    "annotations = []\r\n",
    "\r\n",
    "for i in range(0, len(labels)):\r\n",
    "    fig.add_trace(go.Scatter(x=x_data[i], y=y_data[i], mode='lines',\r\n",
    "        name=labels[i], line=dict(color=colors[i]), connectgaps=True ))\r\n",
    "    # endpoints\r\n",
    "    if i==1:\r\n",
    "        fig.add_trace(go.Scatter(x=x_data[i], y=y_data[i],\r\n",
    "            mode='markers+text', marker=dict(color=colors[i]),\r\n",
    "            text=y_data[i] , textposition=\"top center\"))\r\n",
    "    else:\r\n",
    "        fig.add_trace(go.Scatter(x=x_data[i], y=y_data[i],\r\n",
    "            mode='markers+text', marker=dict(color=colors[i]),\r\n",
    "            text=y_data[i] , textposition=\"bottom center\"))\r\n",
    "    \r\n",
    "    # Name of lines\r\n",
    "    if i != 0:\r\n",
    "        annotations.append(dict(text=labels[i],showarrow=False,\r\n",
    "            xref='x', x=x_data[i,1]-0.1, y=y_data[i,1]+0.1, xanchor='right', yanchor='middle', \r\n",
    "            font=dict(family=\"Bahnschrift\",size=16,color=colors[i])))\r\n",
    "    if i == 0:\r\n",
    "        annotations.append(dict(text=labels[i],showarrow=False,\r\n",
    "            xref='x', x=x_data[i,1]-0.1, y=-y_data[i,1]+0.15, xanchor='right', yanchor='middle', \r\n",
    "            font=dict(family=\"Bahnschrift\",size=16,color=colors[i])))\r\n",
    "\r\n",
    "fig.update_layout(annotations=annotations)\r\n",
    "\r\n",
    "fig.update_layout(\r\n",
    "    xaxis_title=\"year\",\r\n",
    "    yaxis_title=\"€/h\",\r\n",
    "    xaxis=dict(showline=True, showticklabels=True, ticks='outside',\r\n",
    "        linecolor='rgb(204, 204, 204)', linewidth=2, dtick = 1),\r\n",
    "    yaxis=dict(showline=True, showticklabels=True, ticks='outside', \r\n",
    "        linecolor='rgb(204, 204, 204)', linewidth=2, dtick = 1),\r\n",
    "        # ,range = [0, max(df_sex['Value']*1.5)], zeroline=True),\r\n",
    "    showlegend=False,\r\n",
    "    plot_bgcolor='white',\r\n",
    "    font=dict(family=\"Bahnschrift\",size=10,color=\"grey\"),\r\n",
    "    width=800, height=500\r\n",
    ")\r\n",
    "\r\n",
    "fig.show()\r\n",
    "\r\n",
    "# Export the figure\r\n",
    "if exportFigure:\r\n",
    "    fig.write_image(f\"{figureOutputFolder}/question 2/genderGapLine{year}.svg\")\r\n",
    "    fig.write_image(f\"{figureOutputFolder}/question 2/genderGapLine{year}.png\", width=outputWidthImage, height=outputHeightImage)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 3\r\n",
    "What are the sectors for which the salaries in private companies are highest in Italy?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import plotly.graph_objects as go"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_sectors_tot = df_sectors.query('Sesso==\"totale\" & `Classe di età`==\"totale\" & \\\r\n",
    "                              `Classe di dipendenti`==\"totale\" & `Qualifica contrattuale`==\"totale\"'\r\n",
    "                              )[['Ateco 2007','TIME','Value']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot horizontal bar chart for sectors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "long_names = [\r\n",
    "    'Supply of electricity, gas, steam and air conditioning',\r\n",
    "    'Activities of accommodation and catering services',\r\n",
    "    'Other services activities',\r\n",
    "    'Financial and insurance<br> activities',\r\n",
    "    'Rental, travel agencies, business support services'\r\n",
    "    ]\r\n",
    "br_names = [\r\n",
    "    'Supply of electricity, gas,<br> steam and air conditioning',\r\n",
    "    'Activities of accommodation<br> and catering services',\r\n",
    "    'Other services activities',\r\n",
    "    'Financial and insurance activities',\r\n",
    "    'Rental, travel agencies,<br> business support services'\r\n",
    "    ]\r\n",
    "for i in range(0, len(long_names)):\r\n",
    "    df_sectors_tot.loc[df_sectors_tot['Ateco 2007']==long_names[i],\"Ateco 2007\"] = br_names[i]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "howManyEls=2\r\n",
    "df_new = pd.DataFrame(columns=['Ateco 2007','TIME','Value'])\r\n",
    "val_x_axis = max(df_sectors_tot['Value'])\r\n",
    "\r\n",
    "for year in range(2014,2018,1):\r\n",
    "  tmp = df_sectors_tot.query(f'TIME=={year}').sort_values(by='Value')\r\n",
    "  df_new = df_new.append(tmp.head(howManyEls))\r\n",
    "  \r\n",
    "  others = {'Ateco 2007':['Others'],'TIME':[year],'Value':[round(np.average(tmp.head(-howManyEls).tail(-howManyEls)[\"Value\"]),2)]}\r\n",
    "  tmp_others = pd.DataFrame(others,columns=['Ateco 2007','TIME','Value'])\r\n",
    "  df_new = df_new.append(tmp_others)\r\n",
    "  \r\n",
    "  df_new = df_new.append(tmp.tail(howManyEls))\r\n",
    "\r\n",
    "  # df_new = df_new.sort_values(by='Value').reset_index()\r\n",
    "\r\n",
    "  fig = px.bar(df_new.query(f'TIME=={year}'), x=\"Value\", y=\"Ateco 2007\", text=\"Value\")\r\n",
    "\r\n",
    "  fig.update_traces(texttemplate='%{text:.2f} ', textposition='inside')\r\n",
    "\r\n",
    "  fig.update_traces(marker_color=colors_palette[4])\r\n",
    "                  # , marker_line_color='rgb(8,48,107)',marker_line_width=1.5, opacity=0.6)\r\n",
    "  # fig.update_layout(title_text='Sectors with higher salary')\r\n",
    "\r\n",
    "  fig.update_layout(\r\n",
    "    title_text=f'{year}',\r\n",
    "    yaxis_title=None,\r\n",
    "    xaxis_title=\"€/h\",\r\n",
    "    xaxis=dict(showline=True, showticklabels=True, ticks='outside',\r\n",
    "      linecolor='rgb(204, 204, 204)', linewidth=2, dtick = 5,\r\n",
    "      range = [0, val_x_axis]),\r\n",
    "    yaxis=dict( showgrid=False, showline=False, ),\r\n",
    "    paper_bgcolor='white',\r\n",
    "    plot_bgcolor='white',\r\n",
    "    showlegend=False,\r\n",
    "    width=800, height=350\r\n",
    "    )\r\n",
    "  \r\n",
    "  fig.show()\r\n",
    "\r\n",
    "  # Export the figure\r\n",
    "  if exportFigure:\r\n",
    "    fig.write_image(f\"{figureOutputFolder}/question 3/barChartSectors{year}.svg\")\r\n",
    "    fig.write_image(f\"{figureOutputFolder}/question 3/barChartSectors{year}.png\", width=outputWidthImage, height=outputHeightImage)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot with slider"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "howManyEls=3\r\n",
    "df_new = pd.DataFrame(columns=['Ateco 2007','TIME','Value'])\r\n",
    "\r\n",
    "for year in range(2014,2018,1):\r\n",
    "  tmp = df_sectors_tot.query(f'TIME=={year}').sort_values(by='Value')\r\n",
    "  df_new = df_new.append(tmp.head(howManyEls))\r\n",
    "  \r\n",
    "  others = {'Ateco 2007':['Others'],'TIME':[year],'Value':[round(np.average(tmp.head(-howManyEls).tail(-howManyEls)[\"Value\"]),2)]}\r\n",
    "  tmp_others = pd.DataFrame(others,columns=['Ateco 2007','TIME','Value'])\r\n",
    "  df_new = df_new.append(tmp_others)\r\n",
    "  \r\n",
    "  df_new = df_new.append(tmp.tail(howManyEls))\r\n",
    "\r\n",
    "df_new = df_new.sort_values(by='Value').reset_index()\r\n",
    "\r\n",
    "fig = px.bar(df_new, x=\"Value\", y=\"Ateco 2007\", text=\"Value\",\r\n",
    "  animation_frame=\"TIME\", range_x=[0,df_new['Value'].max()*1.1])\r\n",
    "\r\n",
    "fig.update_traces(texttemplate='%{text:.2f} ', textposition='inside')\r\n",
    "\r\n",
    "fig.update_layout(\r\n",
    "      xaxis=dict( showgrid=False, showline=False ),\r\n",
    "      yaxis=dict( showgrid=False, showline=False, ),\r\n",
    "      paper_bgcolor='rgb(248, 248, 255)',\r\n",
    "      plot_bgcolor='rgb(248, 248, 255)',\r\n",
    "    )\r\n",
    "\r\n",
    "fig.layout.updatemenus[0].buttons[0].args[1]['frame']['duration'] = 1000\r\n",
    "# fig.layout.updatemenus[0].buttons[0].args[1]['transition']['duration'] = 1\r\n",
    "  \r\n",
    "fig.show(\"notebook\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit (windows store)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "0a7bcdce5e7de3fa1d95f97898f0ba64b04cd3f3c86a5acc783c9d14c07e9707"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}